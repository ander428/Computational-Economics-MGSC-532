{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "cudagpu",
   "display_name": "cudagpu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exam 1\n",
    "## Joshua Anderson"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1(a) Suppose we run a Monte Carlo simulation and draw n samples uniformly from \\[ 0, 1 \\]. Let $x_i$ be the ith sample. Write the formula for the estimate of the integral of f(x).\n",
    "\n",
    "integral of f(x) = $\\int_{0}^{0.5} 2-8x^{2}\\ dx + \\int_{0.5}^{1} 0\\ dx$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1(b)  For an estimate with 10 samples, on average, how many of the xi’s be below 0.5? What is the upperbound for the number of samples below 0.5? What is the lower bound?\n",
    "\n",
    "Samples below 0.5 on average will be 5 for ten samples as the samples are drawn uniformially. The upper bound would be 10 and the lower bound would be 0 samples."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1(c) Suppose we only draw 5 samples uniformly, and then use antithetic draws for the other 5. Give an example of what the 10 $x_i$’s could look like.\n",
    "\n",
    "The antithetic sample would be $1-x_i$. So if we had 5 samples of \\[0.2, 0.4, 0.5, 0, 1\\], the antithetic samples would be \\[0.8, 0.6, 0.5, 1, 0\\].\n",
    "\n",
    "The full sample would be \\[0.2, 0.4, 0.5, 0, 1, 0.8, 0.6, 0.5, 1, 0\\]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1(d) Using the method in part c, on average, how many will be below 0.5? What is the upper bound for the number below 0.5? What is the lower bound?\n",
    "\n",
    "Using the antithetic method, we should expect on average 5 samples below 0.5 if we are estimating 10 samples. The upper bound would be 5 and the lower bound would be 5."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1(e) Would antithetic sampling reduce the variance of the estimate? Use Monte Carlo methods with both sampling methods and report on the variance of each method in your answer. (Hint: you will want to run multiple small sample Monte Carlo methods)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Variance for random method: 0.0245\n",
      "Variance for antithetic method: 0.0123\n",
      "\n",
      "The antithetic method does reduce the variance in the estimate.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    if x <= 0.5:\n",
    "        return 2 - (8 * x**2)\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "def area_random(samples):\n",
    "    count = 0\n",
    "    for _ in range(samples):\n",
    "        x = random.random()\n",
    "        count += f(x) > random.random()\n",
    "        # else: count += 0 > random.random() would always be 0 so no code is needed\n",
    "    return count / samples\n",
    "\n",
    "def area_antithetic(samples):\n",
    "    count = 0\n",
    "    for _ in range(samples//2):\n",
    "        x = random.random()\n",
    "        antithetic = 1-x\n",
    "        if x <= 0.5:\n",
    "            count += f(x) > random.random()\n",
    "            count += f(antithetic) > random.random()\n",
    "        # again, when x > 0.5 the area will always be 0; no else needed\n",
    "    return count / samples\n",
    "\n",
    "trials = 100000\n",
    "samples = 10\n",
    "\n",
    "reults_random = [area_random(samples) for _ in range(trials)]\n",
    "print(\"Variance for random method:\", round(np.var(reults_random), 4))\n",
    "\n",
    "results_antithetic = [area_antithetic(samples) for _ in range(trials)]\n",
    "print(\"Variance for antithetic method:\", round(np.var(results_antithetic), 4))\n",
    "print()\n",
    "print(\"The antithetic method does reduce the variance in the estimate.\")"
   ]
  },
  {
   "source": [
    "#### 1(f) Using the idea of importance sampling, draw samples from the uniform distribution between 0 and 0.5 such that $x ∼ U_0^{0.5}$. What is the formula for the integral of f(x) when you use this distribution?\n",
    "\n",
    "Given:\n",
    "\n",
    "$\n",
    "f(x) = \\left\\{\\begin{array}{ll}\n",
    "      2-8x^{2} & x\\leq 0.5 \\\\\n",
    "      0 & 0.5 < x \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$,\n",
    "$p(x) = U_0^{0.5}$,\n",
    "$q(x) = U_{0.5}^{1}$\n",
    "\n",
    "The integral is constructed as:\n",
    "\n",
    "$E[f(x)] = \\int f(x)\\frac{U_0^{0.5}}{U_{0.5}^{1}}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1(g). Is importance sampling better, worse, or the same compared to antithetic sampling? Why? Again, use Monte Carlo methods to compare importance sampling with antithetic sampling and the explain the results to answer the \"why?\" portion of the question."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimate for antithetic method: 0.22\nVariance for antithetic method: 0.0123\nEstimate for importance method: -2.03\nVariance for importance method: 236.4207\n\nThe importance sampling method is much worse. This is likely because the distributions do not overlap well. Using the distribution from 0.5 < x <= 1, we do not have a good representation of the distribution from 0 < x <= 0.5. The reason antithetic works much better is that for every sample it takes from the first interval [0,0.5] and samples from the second (0.5,1]. Since the distributions are so different on those intervals, the antithetic sampling gives a much better variance and estimate.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# The target uniform distribution between 0 and 0.5 will have a mean of 0.25 and a variance of 1\n",
    "# Our approximate distribution is the uniform distribution between 0.5 and 1 has a mean of 0.75 and variance of 1\n",
    "target_mean = 0.25\n",
    "target_var = 1\n",
    "approx_mean = 0.75\n",
    "approx_var = 1\n",
    "\n",
    "p_x = stats.norm(target_mean, target_var)\n",
    "q_x = stats.norm(approx_mean, approx_var)\n",
    "\n",
    "trials = 1000\n",
    "\n",
    "results_imp = []\n",
    "for i in range(trials):\n",
    "    x_i = np.random.normal(approx_mean, approx_var)\n",
    "    value = f(x_i)*(p_x.pdf(x_i) / q_x.pdf(x_i))\n",
    "    results_imp.append(value)\n",
    "\n",
    "# we already have the variance from the antithetic sampling\n",
    "print(\"Estimate for antithetic method:\", round(np.mean(results_antithetic),2))\n",
    "print(\"Variance for antithetic method:\", round(np.var(results_antithetic), 4))\n",
    "print(\"Estimate for importance method:\", round(np.mean(results_imp),2))\n",
    "print(\"Variance for importance method:\", round(np.var(results_imp), 4))\n",
    "print()\n",
    "print(\"The importance sampling method is much worse. This is likely because the distributions do not overlap well. Using the distribution from 0.5 < x <= 1, we do not have a good representation of the distribution from 0 < x <= 0.5. The reason antithetic works much better is that for every sample it takes from the first interval [0,0.5] and samples from the second (0.5,1]. Since the distributions are so different on those intervals, the antithetic sampling gives a much better variance and estimate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.linear_solver import pywraplp\n",
    "\n",
    "solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "\n",
    "class Shipment:\n",
    "    def __init__(self, name, cost, profit):\n",
    "        self.name = name\n",
    "        self.cost = cost\n",
    "        self.profit = profit\n",
    "\n",
    "shipments = [Shipment('Livestock_1', 22500, 6), Shipment('Livestock_2', 22500, 6), Shipment('Biohazard_1', 38000, 8), Shipment('Biohazard_2', 38000, 8)]\n",
    "\n",
    "shipment_variables = [solver.IntVar(0,1, shipment.name) for shipment in shipments]\n"
   ]
  },
  {
   "source": [
    "#### 2(a) Variables: \n",
    "\n",
    "$L_1$ - Number of livestock shipment hours in warehouse 1\n",
    "\n",
    "$B_1$ - Number of biohazard shipment hours in warehouse 1\n",
    "\n",
    "$L_2$ - Number of livestock shipment hours in warehouse 2\n",
    "\n",
    "$B_2$ - Number of biohazard shipment hours in warehouse 2\n",
    "\n",
    "#### 2(b) Objective function: \n",
    "\n",
    "$max((104*6)L_1 + (76*8)B_1 + (84*6)L_2 + (46*8)B_2)$\n",
    "\n",
    "#### 2(c) Constraints:\n",
    "\n",
    "$L_1 + B_1 \\leq 240$\n",
    "\n",
    "$L_2 + B_2 \\leq 360$\n",
    "\n",
    "if $L_1$ >= 1, then subtract 22500\n",
    "if $L_2$ >= 1, then subtract 22500\n",
    "if $B_1$ >= 1, then subtract 38000\n",
    "if $B_2$ >= 1, then subtract 38000"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}